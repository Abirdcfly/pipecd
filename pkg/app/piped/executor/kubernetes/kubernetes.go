// Copyright 2020 The PipeCD Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package kubernetes

import (
	"context"
	"fmt"
	"os"
	"path/filepath"

	"go.uber.org/zap"

	"github.com/kapetaniosci/pipe/pkg/app/piped/executor"
	"github.com/kapetaniosci/pipe/pkg/app/piped/toolregistry"
	"github.com/kapetaniosci/pipe/pkg/config"
	"github.com/kapetaniosci/pipe/pkg/model"
)

const (
	PredefinedLabelManagedBy      = "pipecd.dev/managed-by"           // Always be pipecd.
	PredefinedLabelApplication    = "pipecd.dev/application"          // The application this resource belongs to.
	PredefinedLabelVariant        = "pipecd.dev/variant"              // Variant name: primary, stage, baseline
	PredefinedLabelCommitHash     = "pipecd.dev/commit-hash"          // Hash value of the deployed commit.
	PredefinedLabelResourceKey    = "pipecd.dev/resource-key"         // The resource key generated by apiVersion, namespace and name. e.g. apps/v1/Deployment/namespace/demo-app
	PredefinedLabelOriginalAPIKey = "pipecd.dev/original-api-version" // The api version defined in git configuration. e.g. apps/v1

	managedByPiped        = "piped"
	primaryVariant        = "primary"
	stageVariant          = "stage"
	baselineVariant       = "baseline"
	kustomizationFileName = "kustomization.yaml"
)

type TemplatingMethod string

const (
	TemplatingMethodHelm      TemplatingMethod = "helm"
	TemplatingMethodKustomize TemplatingMethod = "kustomize"
	TemplatingMethodNone      TemplatingMethod = "none"
)

type Executor struct {
	executor.Input

	appDirPath       string
	templatingMethod TemplatingMethod
	config           *config.KubernetesDeploymentSpec
	stageConfig      *config.PipelineStage
}

type registerer interface {
	Register(stage model.Stage, f executor.Factory) error
}

func Register(r registerer) {
	f := func(in executor.Input) executor.Executor {
		return &Executor{
			Input: in,
		}
	}
	r.Register(model.StageK8sPrimaryUpdate, f)
	r.Register(model.StageK8sStageRollout, f)
	r.Register(model.StageK8sStageClean, f)
	r.Register(model.StageK8sBaselineRollout, f)
	r.Register(model.StageK8sBaselineClean, f)
	r.Register(model.StageK8sTrafficSplit, f)
}

func (e *Executor) Execute(ctx context.Context) model.StageStatus {
	e.appDirPath = filepath.Join(e.RepoDir, e.Deployment.GitPath.Path)
	e.templatingMethod = determineTemplatingMethod(e.DeploymentConfig, e.appDirPath)

	e.config = e.DeploymentConfig.KubernetesDeploymentSpec
	if e.config == nil {
		e.LogPersister.AppendError(fmt.Sprintf("Malformed deployment configuration: missing KubernetesDeploymentSpec"))
		return model.StageStatus_STAGE_FAILURE
	}

	stageConfig, ok := e.config.GetStage(int(e.Stage.Index))
	if !ok {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to find the stage configuration"))
		return model.StageStatus_STAGE_FAILURE
	}
	e.stageConfig = &stageConfig

	e.Logger.Info("start executing kubernetes stage",
		zap.String("stage-name", e.Stage.Name),
		zap.String("app-dir-path", e.appDirPath),
		zap.String("templating-method", string(e.templatingMethod)),
	)

	switch model.Stage(e.Stage.Name) {
	case model.StageK8sPrimaryUpdate:
		return e.ensurePrimaryUpdate(ctx)
	case model.StageK8sStageRollout:
		return e.ensureStageRollout(ctx)
	case model.StageK8sStageClean:
		return e.ensureStageClean(ctx)
	case model.StageK8sBaselineRollout:
		return e.ensureBaselineRollout(ctx)
	case model.StageK8sBaselineClean:
		return e.ensureBaselineClean(ctx)
	case model.StageK8sTrafficSplit:
		return e.ensureTrafficSplit(ctx)
	}

	e.LogPersister.AppendError(fmt.Sprintf("Unsupported stage %s for kubernetes application", e.Stage.Name))
	return model.StageStatus_STAGE_FAILURE
}

func (e *Executor) ensurePrimaryUpdate(ctx context.Context) model.StageStatus {
	kubectl, err := e.findKubectl(ctx, e.config.Input.KubectlVersion)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to find kubectl (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	manifests, err := e.loadManifests(ctx)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to load kubernetes manifests (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	if len(manifests) == 0 {
		e.LogPersister.AppendError("No kubernetes manifests to handle")
		return model.StageStatus_STAGE_FAILURE
	}

	for _, m := range manifests {
		// Add variant label to PRIMARY workload.
		// if m.Kind == "Deployment" {
		// 	if err := m.AddVariantLabel(primaryVariant); err != nil {
		// 		e.LogPersister.AppendError(fmt.Sprintf("Unabled to configure variant label for %s deployment (%v)", m.Name, err))
		// 		return model.StageStatus_STAGE_FAILURE
		// 	}
		// }

		m.AddAnnotations(map[string]string{
			PredefinedLabelManagedBy:      managedByPiped,
			PredefinedLabelApplication:    e.Deployment.ApplicationId,
			PredefinedLabelVariant:        primaryVariant,
			PredefinedLabelOriginalAPIKey: m.APIVersion,
			PredefinedLabelResourceKey:    m.ResourceKey(),
			PredefinedLabelCommitHash:     e.Deployment.Trigger.Commit.Hash,
		})
	}

	e.LogPersister.AppendInfo(fmt.Sprintf("Updating %d primary resources", len(manifests)))
	if err = kubectl.Apply(ctx, manifests); err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to update primary variant (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	e.LogPersister.AppendSuccess(fmt.Sprintf("Successfully updated %d primary resources", len(manifests)))
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureStageRollout(ctx context.Context) model.StageStatus {
	kubectl, err := e.findKubectl(ctx, e.config.Input.KubectlVersion)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to find kubectl (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	manifests, err := e.loadManifests(ctx)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to load kubernetes manifests (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	if len(manifests) == 0 {
		e.LogPersister.AppendError("No kubernetes manifests to handle")
		return model.StageStatus_STAGE_FAILURE
	}

	stageManifests, err := e.generateStageManifests(ctx, manifests)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to generate manifests for STAGE variant (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	e.LogPersister.AppendInfo("Rolling out STAGE variant")
	if err = kubectl.Apply(ctx, stageManifests); err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Unabled to rollout STAGE variant (%v)", err))
		return model.StageStatus_STAGE_FAILURE
	}

	e.LogPersister.AppendSuccess("Successfully rolled out STAGE variant")
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureStageClean(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureBaselineRollout(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureBaselineClean(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureTrafficSplit(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) ensureRollback(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) generateStageManifests(ctx context.Context, manifests []Manifest) ([]Manifest, error) {
	// List of default configurations.
	var (
		suffix           = "stage"
		workloadKind     = "Deployment"
		workloadName     = ""
		workloadReplicas = 1
		foundWorkload    = false
		stageManifests   []Manifest
	)

	// Apply the specified configuration if they are present.
	if sc := e.config.StageVariant; sc != nil {
		if sc.Suffix != "" {
			suffix = sc.Suffix
		}
		if sc.Workload.Kind != "" {
			workloadKind = sc.Workload.Kind
		}
		if sc.Workload.Name != "" {
			workloadName = sc.Workload.Name
		}
	}

	findWorkload := func(m Manifest) error {
		if m.Kind != workloadKind {
			return nil
		}
		if workloadName != "" && m.Name != workloadName {
			return nil
		}
		var (
			name     = m.Name + "-" + suffix
			manifest = m.Duplicate(name)
		)
		if err := m.AddVariantLabel(stageVariant); err != nil {
			return err
		}
		m.SetReplicas(workloadReplicas)
		stageManifests = append(stageManifests, manifest)
		foundWorkload = true
		return nil
	}

	for _, m := range manifests {
		if err := findWorkload(m); err != nil {
			return nil, err
		}
	}

	if !foundWorkload {
		return nil, fmt.Errorf("unabled to detect workload manifest for STAGE variant")
	}

	for _, m := range manifests {
		m.Name = m.Name + "-" + suffix
		m.AddAnnotations(map[string]string{
			PredefinedLabelManagedBy:      managedByPiped,
			PredefinedLabelApplication:    e.Deployment.ApplicationId,
			PredefinedLabelVariant:        stageVariant,
			PredefinedLabelOriginalAPIKey: m.APIVersion,
			PredefinedLabelResourceKey:    m.ResourceKey(),
			PredefinedLabelCommitHash:     e.Deployment.Trigger.Commit.Hash,
		})
	}
	return stageManifests, nil
}

func (e *Executor) generateBaselineManifests(ctx context.Context) model.StageStatus {
	return model.StageStatus_STAGE_SUCCESS
}

func (e *Executor) findKubectl(ctx context.Context, version string) (*Kubectl, error) {
	path, installed, err := toolregistry.DefaultRegistry().Kubectl(ctx, version)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Failed while installing kubectl %s (%v)", version, err))
		return nil, err
	}
	if installed {
		e.LogPersister.AppendInfo(fmt.Sprintf("Kubectl %s has just been installed because of no pre-installed binary for that version", version))
	}
	return &Kubectl{
		execPath: path,
	}, nil
}

func (e *Executor) findKustomize(ctx context.Context, version string) (*Kustomizectl, error) {
	path, installed, err := toolregistry.DefaultRegistry().Kustomize(ctx, version)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Failed while installing kustomize %s (%v)", version, err))
		return nil, err
	}
	if installed {
		e.LogPersister.AppendInfo(fmt.Sprintf("Kustomize %s has just been installed because of no pre-installed binary for that version", version))
	}
	return &Kustomizectl{
		execPath: path,
	}, nil
}

func (e *Executor) findHelm(ctx context.Context, version string) (*Helmctl, error) {
	path, installed, err := toolregistry.DefaultRegistry().Helm(ctx, version)
	if err != nil {
		e.LogPersister.AppendError(fmt.Sprintf("Failed while installing helm %s (%v)", version, err))
		return nil, err
	}
	if installed {
		e.LogPersister.AppendInfo(fmt.Sprintf("Helm %s has just been installed because of no pre-installed binary for that version", version))
	}
	return &Helmctl{
		execPath: path,
	}, nil
}

func determineTemplatingMethod(deploymentConfig *config.Config, appDirPath string) TemplatingMethod {
	input := deploymentConfig.KubernetesDeploymentSpec.Input
	if input.HelmChart != nil {
		return TemplatingMethodHelm
	}
	if len(input.HelmValueFiles) > 0 {
		return TemplatingMethodHelm
	}
	if input.HelmVersion != "" {
		return TemplatingMethodHelm
	}
	if _, err := os.Stat(filepath.Join(appDirPath, kustomizationFileName)); err == nil {
		return TemplatingMethodKustomize
	}
	return TemplatingMethodNone
}
