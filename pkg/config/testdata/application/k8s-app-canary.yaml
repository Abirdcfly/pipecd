# Progressive delivery with canary strategy.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      # Deploy the workloads of STAGE variant. In this case, the number of
      # workload replicas of STAGE variant is 10% of the replicas number of PRIMARY variant.
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 10%
      # Update the workload of PRIMARY variant to the new version.
      - name: K8S_PRIMARY_UPDATE
      # Destroy all workloads of STAGE variant.
      - name: K8S_STAGE_CLEAN

---
# Progressive delivery with canary strategy.
# This also adds an Approval stage to wait until got
# an approval from one of the specified approvers.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 2
      - name: WAIT_APPROVAL
        with:
          approvers:
            - user-foo
            - user-bar
      - name: K8S_PRIMARY_UPDATE
      - name: K8S_STAGE_CLEAN

---
# Progressive delivery with canary strategy.
# This has an Analysis stage for verifying the deployment process.
# The analysis is just based on the metrics, log, http response from canary version.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 10%
      - name: ANALYSIS
        with:
          duration: 10m
          threshold: 2
          metrics:
            - query: grpc_error_percentage
              expected: < 0.1
              interval: 1m
              provider: prometheus-dev
          logs:
            - query: 'logName = "projects/demo/logs/error'
              interval: 1m
              provider: stackdriver-dev
          https:
            - url: https://canary-endpoint.dev
              method: GET
              expected: 200
              interval: 1m
      - name: K8S_PRIMARY_UPDATE
      - name: K8S_STAGE_CLEAN

---
# Progressive delivery with canary strategy.
# The canary process has multiple phases: from 10% then analysis
# then up to 20% then analysis then 100%.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 10%
      - name: ANALYSIS
        with:
          duration: 10m
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 20%
      - name: ANALYSIS
        with:
          duration: 10m
      - name: K8S_PRIMARY_UPDATE
      - name: K8S_STAGE_CLEAN

---
# Progressive delivery with canary strategy.
# This has an Analysis stage for verifying the deployment process.
# The analysis stage is configured to use metrics templates at .pipe directory.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 10%
      - name: ANALYSIS
        with:
          duration: 10m
          threshold: 2
          metrics:
            - useTemplate: prometheus_grpc_error_percentage
            - useTemplate: prometheus_app_http_error_percentage
          logs:
            - useTemplate: stackdriver_log_error
          https:
            - useTemplate: http_canary_check
      - name: K8S_PRIMARY_UPDATE
      - name: K8S_STAGE_CLEAN

---
# Canary deployment that has an analysis stage to verify canary.
# This deploys both canary and baseline version.
# The baseline pod is a pod that is based on our currently running production version.
# We want to collect metrics against a “new” copy of our old container so
# we don’t muddy the waters testing against a pod that might have been running for a long time.
# The analysis stage is based on the comparision between baseline and stage workloads.
apiVersion: pipecd.dev/v1beta1
kind: KubernetesApp
spec:
  pipeline:
    stages:
      - name: K8S_BASELINE_ROLLOUT
        with:
          replicas: 10%
      - name: K8S_STAGE_ROLLOUT
        with:
          replicas: 10%
      - name: ANALYSIS
        with:
          duration: 10m
          compareWithBaseline: true
      - name: K8S_PRIMARY_UPDATE
      - name: K8S_BASELINE_CLEAN
      - name: K8S_STAGE_CLEAN

# Stage represents a temporary desired state for the applicaiton.
# Users can declarative a list of stages to archive the final desired state.
# This is a pod that is based on our currently running production version.
# We want to collect metrics against a “new” copy of our old container so
# we don’t muddy the waters testing against a pod that might have been running for a long time.
# https://www.spinnaker.io/guides/user/canary/best-practices/#compare-canary-against-baseline-not-against-production
# K8S_BASELINE_ROLLOUT

# Requirements:
# Multiple canary stages
# Automated analysis
# - between baseline and canary
# - based on metrics, logs of only canary
# Various targets: deployment, daemonset, statefulset

#   # List of deployments for the same commit
#   # that must be succeeded before running the deployment for this application.
#   requireDeployments:
#     - app: demoapp
#       env: dev
#     - app: anotherapp
#   # Make a pull request to promote other applicationzwww
#   # (or promote changes through environments of the same application)
#   # after the success of this deployment.
#   promote:
#     - app: demoapp
#       env: prod
#       transforms:
#       - source: pipe.yaml
#         destination: pipe.yaml
#         regex: git@github.com:org/config-repo.git:charts/demoapp?ref=(.*)
#         replacement: git@github.com:org/config-repo.git:charts/demoapp?ref={{ $1 }}
#       pullRequest:
#         title: Update demoapp service in prod
#         commit: Update demo app service in prod
#         desc: |
#           Update demoapp service to {{ .App.Input.Version }}
